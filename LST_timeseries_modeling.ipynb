{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSC Project 2021 Land Sat Temp Machine Learning (oabreu_sjaisha_gdmorrison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by reading our Landsat Images Dataframe composed of all the features we extracted/engineered using parallelization from the band data into the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ndvi</th>\n",
       "      <th>ndsi</th>\n",
       "      <th>ndbi</th>\n",
       "      <th>albedo</th>\n",
       "      <th>awei</th>\n",
       "      <th>gemi</th>\n",
       "      <th>LST</th>\n",
       "      <th>ndvi_lag</th>\n",
       "      <th>ndsi_lag</th>\n",
       "      <th>ndbi_lag</th>\n",
       "      <th>albedo_lag</th>\n",
       "      <th>awei_lag</th>\n",
       "      <th>gemi_lag</th>\n",
       "      <th>LST_lag</th>\n",
       "      <th>community</th>\n",
       "      <th>period</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.019076</td>\n",
       "      <td>0.153550</td>\n",
       "      <td>-0.163155</td>\n",
       "      <td>0.607362</td>\n",
       "      <td>1.882809</td>\n",
       "      <td>-0.903871</td>\n",
       "      <td>276.523380</td>\n",
       "      <td>0.049917</td>\n",
       "      <td>0.086155</td>\n",
       "      <td>-0.131378</td>\n",
       "      <td>0.501135</td>\n",
       "      <td>1.419662</td>\n",
       "      <td>-0.427217</td>\n",
       "      <td>279.788652</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.083315</td>\n",
       "      <td>0.039830</td>\n",
       "      <td>-0.124366</td>\n",
       "      <td>0.368263</td>\n",
       "      <td>0.914185</td>\n",
       "      <td>0.221260</td>\n",
       "      <td>283.478349</td>\n",
       "      <td>0.139216</td>\n",
       "      <td>0.021040</td>\n",
       "      <td>-0.156492</td>\n",
       "      <td>0.473041</td>\n",
       "      <td>1.328839</td>\n",
       "      <td>-0.409352</td>\n",
       "      <td>282.169624</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.010179</td>\n",
       "      <td>0.169821</td>\n",
       "      <td>-0.172797</td>\n",
       "      <td>0.617248</td>\n",
       "      <td>1.910952</td>\n",
       "      <td>-0.952037</td>\n",
       "      <td>276.519069</td>\n",
       "      <td>0.031010</td>\n",
       "      <td>0.125091</td>\n",
       "      <td>-0.150192</td>\n",
       "      <td>0.543724</td>\n",
       "      <td>1.598575</td>\n",
       "      <td>-0.479277</td>\n",
       "      <td>278.620741</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.037017</td>\n",
       "      <td>0.114391</td>\n",
       "      <td>-0.152306</td>\n",
       "      <td>0.510350</td>\n",
       "      <td>1.426391</td>\n",
       "      <td>-0.223004</td>\n",
       "      <td>279.451761</td>\n",
       "      <td>0.130239</td>\n",
       "      <td>0.011503</td>\n",
       "      <td>-0.139664</td>\n",
       "      <td>0.409243</td>\n",
       "      <td>1.097867</td>\n",
       "      <td>-0.122363</td>\n",
       "      <td>284.583449</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.037763</td>\n",
       "      <td>0.119415</td>\n",
       "      <td>-0.157467</td>\n",
       "      <td>0.485321</td>\n",
       "      <td>1.382989</td>\n",
       "      <td>-0.160794</td>\n",
       "      <td>281.408990</td>\n",
       "      <td>0.114833</td>\n",
       "      <td>0.002798</td>\n",
       "      <td>-0.119861</td>\n",
       "      <td>0.387643</td>\n",
       "      <td>1.017787</td>\n",
       "      <td>-0.038475</td>\n",
       "      <td>286.040619</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      ndvi      ndsi      ndbi    albedo      awei      gemi  \\\n",
       "0           0  0.019076  0.153550 -0.163155  0.607362  1.882809 -0.903871   \n",
       "1           1  0.083315  0.039830 -0.124366  0.368263  0.914185  0.221260   \n",
       "2           2  0.010179  0.169821 -0.172797  0.617248  1.910952 -0.952037   \n",
       "3           3  0.037017  0.114391 -0.152306  0.510350  1.426391 -0.223004   \n",
       "4           4  0.037763  0.119415 -0.157467  0.485321  1.382989 -0.160794   \n",
       "\n",
       "          LST  ndvi_lag  ndsi_lag  ndbi_lag  albedo_lag  awei_lag  gemi_lag  \\\n",
       "0  276.523380  0.049917  0.086155 -0.131378    0.501135  1.419662 -0.427217   \n",
       "1  283.478349  0.139216  0.021040 -0.156492    0.473041  1.328839 -0.409352   \n",
       "2  276.519069  0.031010  0.125091 -0.150192    0.543724  1.598575 -0.479277   \n",
       "3  279.451761  0.130239  0.011503 -0.139664    0.409243  1.097867 -0.122363   \n",
       "4  281.408990  0.114833  0.002798 -0.119861    0.387643  1.017787 -0.038475   \n",
       "\n",
       "      LST_lag  community  period    year  \n",
       "0  279.788652        1.0     1.0  2013.0  \n",
       "1  282.169624        2.0     1.0  2013.0  \n",
       "2  278.620741        3.0     1.0  2013.0  \n",
       "3  284.583449        4.0     1.0  2013.0  \n",
       "4  286.040619        5.0     1.0  2013.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      int64\n",
       "ndvi          float64\n",
       "ndsi          float64\n",
       "ndbi          float64\n",
       "albedo        float64\n",
       "awei          float64\n",
       "gemi          float64\n",
       "LST           float64\n",
       "ndvi_lag      float64\n",
       "ndsi_lag      float64\n",
       "ndbi_lag      float64\n",
       "albedo_lag    float64\n",
       "awei_lag      float64\n",
       "gemi_lag      float64\n",
       "LST_lag       float64\n",
       "community     float64\n",
       "period        float64\n",
       "year          float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ndvi</th>\n",
       "      <th>ndsi</th>\n",
       "      <th>ndbi</th>\n",
       "      <th>albedo</th>\n",
       "      <th>awei</th>\n",
       "      <th>gemi</th>\n",
       "      <th>LST</th>\n",
       "      <th>ndvi_lag</th>\n",
       "      <th>ndsi_lag</th>\n",
       "      <th>ndbi_lag</th>\n",
       "      <th>albedo_lag</th>\n",
       "      <th>awei_lag</th>\n",
       "      <th>gemi_lag</th>\n",
       "      <th>LST_lag</th>\n",
       "      <th>community</th>\n",
       "      <th>period</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1232.000000</td>\n",
       "      <td>1232.000000</td>\n",
       "      <td>1232.000000</td>\n",
       "      <td>1232.000000</td>\n",
       "      <td>1232.000000</td>\n",
       "      <td>1232.000000</td>\n",
       "      <td>1232.000000</td>\n",
       "      <td>1232.000000</td>\n",
       "      <td>1232.000000</td>\n",
       "      <td>1232.000000</td>\n",
       "      <td>1232.000000</td>\n",
       "      <td>1232.000000</td>\n",
       "      <td>1232.000000</td>\n",
       "      <td>1232.000000</td>\n",
       "      <td>1232.000000</td>\n",
       "      <td>1232.000000</td>\n",
       "      <td>1232.000000</td>\n",
       "      <td>1232.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>615.500000</td>\n",
       "      <td>0.138682</td>\n",
       "      <td>-0.064149</td>\n",
       "      <td>-0.129187</td>\n",
       "      <td>0.333211</td>\n",
       "      <td>0.823344</td>\n",
       "      <td>-0.048708</td>\n",
       "      <td>280.961080</td>\n",
       "      <td>0.161439</td>\n",
       "      <td>-0.063259</td>\n",
       "      <td>-0.129450</td>\n",
       "      <td>0.335639</td>\n",
       "      <td>0.829636</td>\n",
       "      <td>-0.050119</td>\n",
       "      <td>281.167063</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2016.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>355.792074</td>\n",
       "      <td>1.178959</td>\n",
       "      <td>0.222542</td>\n",
       "      <td>0.137809</td>\n",
       "      <td>0.205186</td>\n",
       "      <td>0.784641</td>\n",
       "      <td>0.920449</td>\n",
       "      <td>31.625385</td>\n",
       "      <td>0.430596</td>\n",
       "      <td>0.207122</td>\n",
       "      <td>0.094852</td>\n",
       "      <td>0.189502</td>\n",
       "      <td>0.732919</td>\n",
       "      <td>0.807232</td>\n",
       "      <td>29.954097</td>\n",
       "      <td>22.235137</td>\n",
       "      <td>0.500203</td>\n",
       "      <td>2.292218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-28.819356</td>\n",
       "      <td>-1.082993</td>\n",
       "      <td>-2.096368</td>\n",
       "      <td>-0.101832</td>\n",
       "      <td>-0.346372</td>\n",
       "      <td>-6.324060</td>\n",
       "      <td>131.303018</td>\n",
       "      <td>-7.037332</td>\n",
       "      <td>-0.383926</td>\n",
       "      <td>-0.638440</td>\n",
       "      <td>0.096104</td>\n",
       "      <td>0.026513</td>\n",
       "      <td>-4.005951</td>\n",
       "      <td>205.984376</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>307.750000</td>\n",
       "      <td>0.030334</td>\n",
       "      <td>-0.248605</td>\n",
       "      <td>-0.146723</td>\n",
       "      <td>0.150188</td>\n",
       "      <td>0.160786</td>\n",
       "      <td>-0.260273</td>\n",
       "      <td>269.780707</td>\n",
       "      <td>0.049869</td>\n",
       "      <td>-0.243943</td>\n",
       "      <td>-0.136536</td>\n",
       "      <td>0.150030</td>\n",
       "      <td>0.170908</td>\n",
       "      <td>-0.309993</td>\n",
       "      <td>269.668017</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2014.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>615.500000</td>\n",
       "      <td>0.168994</td>\n",
       "      <td>-0.106112</td>\n",
       "      <td>-0.106572</td>\n",
       "      <td>0.250547</td>\n",
       "      <td>0.465112</td>\n",
       "      <td>0.411201</td>\n",
       "      <td>294.762619</td>\n",
       "      <td>0.165653</td>\n",
       "      <td>-0.091342</td>\n",
       "      <td>-0.108709</td>\n",
       "      <td>0.275910</td>\n",
       "      <td>0.572761</td>\n",
       "      <td>0.357113</td>\n",
       "      <td>292.429913</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2016.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>923.250000</td>\n",
       "      <td>0.318900</td>\n",
       "      <td>0.096069</td>\n",
       "      <td>-0.074838</td>\n",
       "      <td>0.514831</td>\n",
       "      <td>1.494611</td>\n",
       "      <td>0.489959</td>\n",
       "      <td>303.859361</td>\n",
       "      <td>0.297884</td>\n",
       "      <td>0.068416</td>\n",
       "      <td>-0.079068</td>\n",
       "      <td>0.488135</td>\n",
       "      <td>1.417710</td>\n",
       "      <td>0.482864</td>\n",
       "      <td>303.415602</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2018.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1231.000000</td>\n",
       "      <td>1.062513</td>\n",
       "      <td>0.564388</td>\n",
       "      <td>1.313699</td>\n",
       "      <td>0.805480</td>\n",
       "      <td>2.988590</td>\n",
       "      <td>0.618389</td>\n",
       "      <td>321.272348</td>\n",
       "      <td>0.550040</td>\n",
       "      <td>0.523617</td>\n",
       "      <td>0.169436</td>\n",
       "      <td>0.748183</td>\n",
       "      <td>2.806167</td>\n",
       "      <td>0.573395</td>\n",
       "      <td>313.722899</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0         ndvi         ndsi         ndbi       albedo  \\\n",
       "count  1232.000000  1232.000000  1232.000000  1232.000000  1232.000000   \n",
       "mean    615.500000     0.138682    -0.064149    -0.129187     0.333211   \n",
       "std     355.792074     1.178959     0.222542     0.137809     0.205186   \n",
       "min       0.000000   -28.819356    -1.082993    -2.096368    -0.101832   \n",
       "25%     307.750000     0.030334    -0.248605    -0.146723     0.150188   \n",
       "50%     615.500000     0.168994    -0.106112    -0.106572     0.250547   \n",
       "75%     923.250000     0.318900     0.096069    -0.074838     0.514831   \n",
       "max    1231.000000     1.062513     0.564388     1.313699     0.805480   \n",
       "\n",
       "              awei         gemi          LST     ndvi_lag     ndsi_lag  \\\n",
       "count  1232.000000  1232.000000  1232.000000  1232.000000  1232.000000   \n",
       "mean      0.823344    -0.048708   280.961080     0.161439    -0.063259   \n",
       "std       0.784641     0.920449    31.625385     0.430596     0.207122   \n",
       "min      -0.346372    -6.324060   131.303018    -7.037332    -0.383926   \n",
       "25%       0.160786    -0.260273   269.780707     0.049869    -0.243943   \n",
       "50%       0.465112     0.411201   294.762619     0.165653    -0.091342   \n",
       "75%       1.494611     0.489959   303.859361     0.297884     0.068416   \n",
       "max       2.988590     0.618389   321.272348     0.550040     0.523617   \n",
       "\n",
       "          ndbi_lag   albedo_lag     awei_lag     gemi_lag      LST_lag  \\\n",
       "count  1232.000000  1232.000000  1232.000000  1232.000000  1232.000000   \n",
       "mean     -0.129450     0.335639     0.829636    -0.050119   281.167063   \n",
       "std       0.094852     0.189502     0.732919     0.807232    29.954097   \n",
       "min      -0.638440     0.096104     0.026513    -4.005951   205.984376   \n",
       "25%      -0.136536     0.150030     0.170908    -0.309993   269.668017   \n",
       "50%      -0.108709     0.275910     0.572761     0.357113   292.429913   \n",
       "75%      -0.079068     0.488135     1.417710     0.482864   303.415602   \n",
       "max       0.169436     0.748183     2.806167     0.573395   313.722899   \n",
       "\n",
       "         community       period         year  \n",
       "count  1232.000000  1232.000000  1232.000000  \n",
       "mean     39.000000     1.500000  2016.500000  \n",
       "std      22.235137     0.500203     2.292218  \n",
       "min       1.000000     1.000000  2013.000000  \n",
       "25%      20.000000     1.000000  2014.750000  \n",
       "50%      39.000000     1.500000  2016.500000  \n",
       "75%      58.000000     2.000000  2018.250000  \n",
       "max      77.000000     2.000000  2020.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('df2.csv')\n",
    "#df.drop(columns = [\"Unnamed: 0\"])\n",
    "display(df.head())\n",
    "display(df.dtypes)\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_split = {0: [[2015], 2016],\n",
    "                 1: [[2015, 2016], 2017],\n",
    "                 2: [[2015, 2016, 2017], 2018],\n",
    "                 3: [[2015, 2016, 2017, 2018], 2019],\n",
    "                 4: [[2015, 2016, 2017, 2018, 2019], 2020]}\n",
    "                 \n",
    "test_year = 2020\n",
    "default_ycol = \"LST\"\n",
    "default_selection_param = \"RMSE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All custom functions for ML modeling\n",
    "def pipe_normalize(df, scaler=None, outputinc=False, outputcol=None):\n",
    "    '''\n",
    "    Normalizes dataframe (adapted from Nick Feamster's normalize function)\n",
    "    Inputs:\n",
    "        df (Pandas Dataframe)\n",
    "        scaler (Scaler) :If scaler is not none, use given scaler's means and sds\n",
    "                         to normalize (input for test set case); else, set \n",
    "                         scaler in function\n",
    "        outputinc (bool): If output is included, set aside to ensure it does not\n",
    "                          get normalized, default False\n",
    "        outputcol (str): If output is included, name of output column, default\n",
    "                         None\n",
    "    Returns tuple of:\n",
    "        Normalized DataFrame and scaler used to normalize DataFrame\n",
    "    '''\n",
    "    columns = df.columns\n",
    "    if outputinc:\n",
    "        outcomes = df.loc[:,outputcol]\n",
    "        df = pd.DataFrame(df.drop(outputcol, axis=1))\n",
    "    if scaler is None:\n",
    "        scaler = StandardScaler()\n",
    "        normalized_features = scaler.fit_transform(df) \n",
    "    else:\n",
    "        normalized_features = scaler.transform(df)\n",
    "\n",
    "    normalized_df = pd.DataFrame(normalized_features)\n",
    "    if outputinc:\n",
    "        normalized_df[outputcol] = outcomes.tolist()\n",
    "\n",
    "    normalized_df.index=df.index\n",
    "    normalized_df.columns= columns\n",
    "\n",
    "    return normalized_df, scaler\n",
    "\n",
    "def train_val_test_split(df, split = default_split, ycol = default_ycol):\n",
    "    k = len(split)\n",
    "\n",
    "    df_train = [pd.DataFrame(columns = list(df.columns))]*k\n",
    "    df_val = [pd.DataFrame(columns = list(df.columns))]*k\n",
    "    df_test = df[df[\"year\"] == test_year]\n",
    "\n",
    "    for i in range(k):\n",
    "        for train_yr in split[i][0]:\n",
    "            df_train[i] = df_train[i].append(df[df[\"year\"] == train_yr])\n",
    "        df_val[i] = df_val[i].append(df[df[\"year\"] == split[i][1]])\n",
    "\n",
    "    df_train_y = [None]*k\n",
    "    df_train_x = [None]*k\n",
    "    df_val_y = [None]*k\n",
    "    df_val_x = [None]*k\n",
    "\n",
    "    for i in range(k):\n",
    "        df_train_y[i] = df_train[i][ycol]\n",
    "        df_train_x[i] = df_train[i].drop(columns = [ycol, \"year\"])\n",
    "        df_val_y[i] = df_val[i][ycol]\n",
    "        df_val_x[i] = df_val[i].drop(columns = [ycol, \"year\"])\n",
    "        df_test_y = df_test[ycol]\n",
    "        df_test_x = df_test.drop(columns = [ycol, \"year\"])\n",
    "\n",
    "    return df_train_y, df_train_x, df_val_y, df_val_x, df_test_y, df_test_x\n",
    "\n",
    "def normalize(df_train_x, df_val_x, df_test_x):\n",
    "    k = len(df_train_x)\n",
    "    train_norm = []\n",
    "    valid_norm = []\n",
    "    for n in range(k):\n",
    "        df = pd.concat((df_train_x[n], df_val_x[n]))\n",
    "        df_norm, scaler = pipe_normalize(df)\n",
    "        tr_norm = df_norm.loc[df_train_x[n].index,:]\n",
    "        val_norm = df_norm.loc[df_val_x[n].index,:]\n",
    "        train_norm.append(tr_norm)\n",
    "        valid_norm.append(val_norm)\n",
    "    te_norm, _ = pipe_normalize(df_test_x, scaler=scaler)\n",
    "    test_norm = te_norm\n",
    "    return train_norm, valid_norm, test_norm\n",
    "\n",
    "def grid_search_time_series_cv(df_train_y, df_train_x, df_val_y, df_val_x,\n",
    "                               models, p_grid, ret_int_results = False, print = False):\n",
    "    k = len(df_train_y)\n",
    "    val_results = [pd.DataFrame(columns = [\"Model\", \"Params\", \"RMSE\", \"MAE\", \"R^2\"])]*k\n",
    "\n",
    "    for i in range(k):\n",
    "        for model_key in models.keys():\n",
    "            for params in p_grid[model_key]:\n",
    "                if print == True:\n",
    "                    print(\"Training model:\", model_key, \"|\", params)\n",
    "                model = models[model_key]\n",
    "                model.set_params(**params)\n",
    "                fitted_model = model.fit(df_train_x[i], df_train_y[i])\n",
    "                test_predictions = fitted_model.predict(df_val_x[i])\n",
    "                rmse = mean_squared_error(df_val_y[i], test_predictions, squared = False)\n",
    "                mae = mean_absolute_error(df_val_y[i], test_predictions)\n",
    "                r2 = r2_score(df_val_y[i], test_predictions)\n",
    "                val_results[i] = val_results[i].append(pd.DataFrame([[model_key, params, rmse, mae, r2]],\n",
    "                                                       columns = [\"Model\", \"Params\", \"RMSE\", \"MAE\", \"R^2\"]))\n",
    "\n",
    "    avg_val_results = pd.DataFrame(columns = [\"Model\", \"Params\", \"RMSE\", \"RMSE std dev\", \"MAE\", \"R^2\"])\n",
    "    avg_val_results[\"Model\"] = val_results[0][\"Model\"]\n",
    "    avg_val_results[\"Params\"] = val_results[0][\"Params\"]\n",
    "    avg_val_results[\"RMSE\"] = [0]*len(val_results[0])\n",
    "    avg_val_results[\"RMSE std dev\"] = [0]*len(val_results[0])\n",
    "    avg_val_results[\"MAE\"] = [0]*len(val_results[0])\n",
    "    avg_val_results[\"R^2\"] = [0]*len(val_results[0])\n",
    "    for i in range(k):\n",
    "        avg_val_results[\"RMSE\"] += val_results[i][\"RMSE\"]/k\n",
    "        avg_val_results[\"MAE\"] += val_results[i][\"MAE\"]/k\n",
    "        avg_val_results[\"R^2\"] += val_results[i][\"R^2\"]/k\n",
    "    avg_val_results = avg_val_results.reset_index().drop(columns = [\"index\"])\n",
    "    l0 = list(val_results[0][\"RMSE\"])\n",
    "    l1 = list(val_results[1][\"RMSE\"])\n",
    "    l2 = list(val_results[0][\"RMSE\"])\n",
    "    for i in range(len(avg_val_results)):\n",
    "        avg_val_results.iloc[i, [3]] = np.std([l0[i], l1[i], l2[i]])\n",
    "\n",
    "    if ret_int_results == True:\n",
    "        return avg_val_results, val_results\n",
    "    else:\n",
    "        return avg_val_results\n",
    "\n",
    "def select_best_model(avg_val_results, selection_param = default_selection_param):\n",
    "    best_model = avg_val_results[avg_val_results[selection_param] == avg_val_results[selection_param].min()].iloc[0]\n",
    "    return best_model\n",
    "\n",
    "def select_model(avg_val_results, row):\n",
    "    chosen_model = avg_val_results.iloc[row]\n",
    "    return chosen_model\n",
    "\n",
    "def test_model(df_train_y, df_train_x, df_val_y, df_val_x, df_test_y, df_test_x,\n",
    "               chosen_model, models):\n",
    "    k = len(df_train_y)\n",
    "    model = models[chosen_model[\"Model\"]]\n",
    "    model.set_params(**chosen_model[\"Params\"])\n",
    "\n",
    "\n",
    "    df_tv_x = pd.concat([df_train_x[k-1], df_val_x[k-1]])\n",
    "    df_tv_y = pd.concat([df_train_y[k-1], df_val_y[k-1]])\n",
    "\n",
    "    fitted_model = model.fit(df_tv_x, df_tv_y)\n",
    "    test_predictions = fitted_model.predict(df_test_x)\n",
    "    rmse = mean_squared_error(df_test_y, test_predictions, squared = False)\n",
    "    mae = mean_absolute_error(df_test_y, test_predictions)\n",
    "    r2 = r2_score(df_test_y, test_predictions)\n",
    "    test_results = {\"RMSE\" : rmse, \"MAE\" : mae, \"r^2\" :r2}\n",
    "    return test_results, df_test_x, df_test_y, test_predictions\n",
    "\n",
    "def choose_and_test_model(df, models, p_grid, default_split, ycol = default_ycol, selection_param = default_selection_param):\n",
    "    df_train_y, df_train_x, df_val_y, df_val_x, df_test_y, df_test_x = train_val_test_split(df, default_split, ycol)\n",
    "    df_train_x, df_val_x, df_test_x = normalize(df_train_x, df_val_x, df_test_x)\n",
    "    print(df_train_x)\n",
    "    avg_val_results = grid_search_time_series_cv(df_train_y, df_train_x, df_val_y, df_val_x, models, p_grid)\n",
    "    best = select_best_model(avg_val_results, selection_param)\n",
    "    test_results, df_test_x, df_test_y, test_predictions = test_model(df_train_y, df_train_x, df_val_y, df_val_x, df_test_y, df_test_x, best, models)\n",
    "    return test_results, best, df_test_x, df_test_y, test_predictions\n",
    "\n",
    "\n",
    "def find_features(df, model_pd):\n",
    "    dfs = train_val_test_split(df)\n",
    "    df_train_y, df_train_x, df_val_y, df_val_x, df_test_y, df_test_x = dfs\n",
    "    df_train_x, df_val_x, df_test_x = normalize(df_train_x,\n",
    "                                                            df_val_x, df_test_x)\n",
    "    k = len(df_train_x)\n",
    "    df_tv_x = [pd.DataFrame(columns = list(df_train_x[0].columns))] * k\n",
    "    df_tv_y = [pd.Series()]*k\n",
    "\n",
    "    for i in range(k):\n",
    "        df_tv_x[i] = df_tv_x[i].append(df_train_x[i]).append(df_val_x[i])\n",
    "        df_tv_y[i] = df_tv_y[i].append(df_train_y[i]).append(df_val_y[i])\n",
    "\n",
    "    model = models[model_pd[\"Model\"]]\n",
    "    params = model_pd[\"Params\"]\n",
    "    model.set_params(**params)\n",
    "    model.fit(df_tv_x[k-1], df_tv_y[k-1])\n",
    "    if model_pd[\"Model\"] == \"RandomForestRegressor\":\n",
    "        features = model.feature_importances_\n",
    "    else:\n",
    "        features = model.coef_\n",
    "        print(model.intercept_)\n",
    "    n = len(features)\n",
    "    coefs = pd.DataFrame(np.round(features.reshape(n, 1), decimals=2),\n",
    "                         index=df_tv_x[k-1].columns, columns=[\"coef\"])\n",
    "    predictions = model.predict(df_test_x)\n",
    "    results = evaluate(df_test_y, predictions)\n",
    "\n",
    "    return coefs.sort_values(by=\"coef\",axis=0, ascending=False), results\n",
    "\n",
    "def evaluate(target_test, target_predict):\n",
    "    '''\n",
    "    Evaluates how well the model did in predicting the wanted outcome through\n",
    "    the Precision, Recall, F1 Score and Accuracy\n",
    "    Inputs:\n",
    "        target_test (Series): Expected outcomes for test data\n",
    "        target_predict (Series): Predicted outcomes for test data\n",
    "    \n",
    "    Returns tuple of Precision, Recall, F1 Score and Accuracy\n",
    "    '''\n",
    "    MSE = metrics.mean_squared_error(target_test, target_predict, squared=False)\n",
    "    MAE = metrics.mean_absolute_error(target_test, target_predict)\n",
    "    R2 = metrics.r2_score(target_test, target_predict)\n",
    "\n",
    "    return MSE, MAE, R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_val_test_split(df, split = default_split, ycol = default_ycol):\n",
    "    k = len(split)\n",
    "\n",
    "    df_train = [pd.DataFrame(columns = list(df.columns))]*k\n",
    "    df_val = [pd.DataFrame(columns = list(df.columns))]*k\n",
    "    df_test = df[df[\"year\"] == test_year]\n",
    "\n",
    "    for i in range(k):\n",
    "        for train_yr in split[i][0]:\n",
    "            df_train[i] = df_train[i].append(df[df[\"year\"] == train_yr])\n",
    "        df_val[i] = df_val[i].append(df[df[\"year\"] == split[i][1]])\n",
    "\n",
    "    df_train_y = [None]*k\n",
    "    df_train_x = [None]*k\n",
    "    df_val_y = [None]*k\n",
    "    df_val_x = [None]*k\n",
    "\n",
    "    for i in range(k):\n",
    "        df_train_y[i] = df_train[i][ycol]\n",
    "        df_train_x[i] = df_train[i].drop(columns = [ycol, \"year\"])\n",
    "        df_val_y[i] = df_val[i][ycol]\n",
    "        df_val_x[i] = df_val[i].drop(columns = [ycol, \"year\"])\n",
    "        df_test_y = df_test[ycol]\n",
    "        df_test_x = df_test.drop(columns = [ycol, \"year\"])\n",
    "\n",
    "    return df_train_y, df_train_x, df_val_y, df_val_x, df_test_y, df_test_x\n",
    "\n",
    "def normalize(df_train_x, df_val_x, df_test_x, features_list):\n",
    "    k = len(df_train_x)\n",
    "    train_norm = []\n",
    "    valid_norm = []\n",
    "    for n in range(k):\n",
    "        df = pd.concat((df_train_x[n], df_val_x[n]))\n",
    "        df_norm, scaler = pipe_normalize(df, features_list)\n",
    "        tr_norm = df_norm.loc[df_train_x[n].index,:]\n",
    "        val_norm = df_norm.loc[df_val_x[n].index,:]\n",
    "        train_norm.append(tr_norm)\n",
    "        valid_norm.append(val_norm)\n",
    "    te_norm, _ = pipe_normalize(df_test_x, features_list, scaler=scaler)\n",
    "    \n",
    "    test_norm = te_norm\n",
    "    return train_norm, valid_norm, test_norm\n",
    "\n",
    "def grid_search_time_series_cv(df_train_y, df_train_x, df_val_y, df_val_x,\n",
    "                               models, p_grid, ret_int_results = False, print = False):\n",
    "    k = len(df_train_y)\n",
    "    val_results = [pd.DataFrame(columns = [\"Model\", \"Params\", \"RMSE\", \"MAE\", \"R^2\"])]*k\n",
    "\n",
    "    for i in range(k):\n",
    "        for model_key in models.keys():\n",
    "            for params in p_grid[model_key]:\n",
    "                if print == True:\n",
    "                    print(\"Training model:\", model_key, \"|\", params)\n",
    "                model = models[model_key]\n",
    "                model.set_params(**params)\n",
    "                fitted_model = model.fit(df_train_x[i], df_train_y[i])\n",
    "                test_predictions = fitted_model.predict(df_val_x[i])\n",
    "                rmse = mean_squared_error(df_val_y[i], test_predictions, squared = False)\n",
    "                mae = mean_absolute_error(df_val_y[i], test_predictions)\n",
    "                r2 = r2_score(df_val_y[i], test_predictions)\n",
    "                val_results[i] = val_results[i].append(pd.DataFrame([[model_key, params, rmse, mae, r2]],\n",
    "                                                       columns = [\"Model\", \"Params\", \"RMSE\", \"MAE\", \"R^2\"]))\n",
    "\n",
    "    avg_val_results = pd.DataFrame(columns = [\"Model\", \"Params\", \"RMSE\", \"RMSE std dev\", \"MAE\", \"R^2\"])\n",
    "    avg_val_results[\"Model\"] = val_results[0][\"Model\"]\n",
    "    avg_val_results[\"Params\"] = val_results[0][\"Params\"]\n",
    "    avg_val_results[\"RMSE\"] = [0]*len(val_results[0])\n",
    "    avg_val_results[\"RMSE std dev\"] = [0]*len(val_results[0])\n",
    "    avg_val_results[\"MAE\"] = [0]*len(val_results[0])\n",
    "    avg_val_results[\"R^2\"] = [0]*len(val_results[0])\n",
    "    for i in range(k):\n",
    "        avg_val_results[\"RMSE\"] += val_results[i][\"RMSE\"]/k\n",
    "        avg_val_results[\"MAE\"] += val_results[i][\"MAE\"]/k\n",
    "        avg_val_results[\"R^2\"] += val_results[i][\"R^2\"]/k\n",
    "    avg_val_results = avg_val_results.reset_index().drop(columns = [\"index\"])\n",
    "    l0 = list(val_results[0][\"RMSE\"])\n",
    "    l1 = list(val_results[1][\"RMSE\"])\n",
    "    l2 = list(val_results[0][\"RMSE\"])\n",
    "    for i in range(len(avg_val_results)):\n",
    "        avg_val_results.iloc[i, [3]] = np.std([l0[i], l1[i], l2[i]])\n",
    "\n",
    "    if ret_int_results == True:\n",
    "        return avg_val_results, val_results\n",
    "    else:\n",
    "        return avg_val_results\n",
    "\n",
    "def select_best_model(avg_val_results, selection_param = default_selection_param):\n",
    "    best_model = avg_val_results[avg_val_results[selection_param] == avg_val_results[selection_param].min()].iloc[0]\n",
    "    return best_model\n",
    "\n",
    "def select_model(avg_val_results, row):\n",
    "    chosen_model = avg_val_results.iloc[row]\n",
    "    return chosen_model\n",
    "\n",
    "def test_model(df_train_y, df_train_x, df_val_y, df_val_x, df_test_y, df_test_x,\n",
    "               chosen_model, models):\n",
    "    k = len(df_train_y)\n",
    "    model = models[chosen_model[\"Model\"]]\n",
    "    model.set_params(**chosen_model[\"Params\"])\n",
    "\n",
    "    df_tv_x = pd.concat([df_train_x[k-1], df_val_x[k-1]])\n",
    "    df_tv_y = pd.concat([df_train_y[k-1], df_val_y[k-1]])\n",
    "\n",
    "    fitted_model = model.fit(df_tv_x, df_tv_y)\n",
    "    test_predictions = fitted_model.predict(df_test_x)\n",
    "    rmse = mean_squared_error(df_test_y, test_predictions, squared = False)\n",
    "    mae = mean_absolute_error(df_test_y, test_predictions)\n",
    "    r2 = r2_score(df_test_y, test_predictions)\n",
    "    test_results = {\"RMSE\" : rmse, \"MAE\" : mae, \"r^2\" :r2}\n",
    "\n",
    "    return test_results, df_test_x, df_test_y, test_predictions\n",
    "\n",
    "def choose_and_test_model(df, models, p_grid, default_split, ycol = default_ycol, selection_param = default_selection_param):\n",
    "    df_train_y, df_train_x, df_val_y, df_val_x, df_test_y, df_test_x = train_val_test_split(df, default_split, ycol)\n",
    "    df_train_x, df_val_x, df_test_x = normalize(df_train_x, df_val_x, df_test_x, features_list)\n",
    "    avg_val_results = grid_search_time_series_cv(df_train_y, df_train_x, df_val_y, df_val_x, models, p_grid)\n",
    "    best = select_best_model(avg_val_results, selection_param)\n",
    "    test_results, df_test_x, df_test_y, test_predictions = test_model(df_train_y, df_train_x, df_val_y, df_val_x, df_test_y, df_test_x, best, models)\n",
    "    return test_results, best, df_test_x, df_test_y, test_predictions\n",
    "\n",
    "def find_features(df, model_pd):\n",
    "    dfs = train_val_test_split(df)\n",
    "    df_train_y, df_train_x, df_val_y, df_val_x, df_test_y, df_test_x = dfs\n",
    "    df_train_x, df_val_x, df_test_x = normalize(df_train_x, df_val_x, df_test_x)\n",
    "    k = len(df_train_x)\n",
    "    df_tv_x = [pd.DataFrame(columns = list(df_train_x[0].columns))] * k\n",
    "    df_tv_y = [pd.Series()]*k\n",
    "\n",
    "    for i in range(k):\n",
    "        df_tv_x[i] = df_tv_x[i].append(df_train_x[i]).append(df_val_x[i])\n",
    "        df_tv_y[i] = df_tv_y[i].append(df_train_y[i]).append(df_val_y[i])\n",
    "\n",
    "    model = models[model_pd[\"Model\"]]\n",
    "    params = model_pd[\"Params\"]\n",
    "    model.set_params(**params)\n",
    "    model.fit(df_tv_x[k-1], df_tv_y[k-1])\n",
    "    if model_pd[\"Model\"] == \"RandomForestRegressor\":\n",
    "        features = model.feature_importances_\n",
    "    else:\n",
    "        features = model.coef_\n",
    "        #print(model.intercept_)\n",
    "    n = len(features)\n",
    "    coefs = pd.DataFrame(np.round(features.reshape(n, 1), decimals=2),\n",
    "                         index=df_tv_x[k-1].columns, columns=[\"coef\"])\n",
    "    predictions = model.predict(df_test_x)\n",
    "    results = evaluate(df_test_y, predictions)\n",
    "\n",
    "    return coefs.sort_values(by=\"coef\",axis=0, ascending=False), results\n",
    "\n",
    "def evaluate(target_test, target_predict):\n",
    "    '''\n",
    "    Evaluates how well the model did in predicting the wanted outcome through\n",
    "    the Precision, Recall, F1 Score and Accuracy\n",
    "    Inputs:\n",
    "        target_test (Series): Expected outcomes for test data\n",
    "        target_predict (Series): Predicted outcomes for test data\n",
    "    \n",
    "    Returns tuple of Precision, Recall, F1 Score and Accuracy\n",
    "    '''\n",
    "    MSE = metrics.mean_squared_error(target_test, target_predict, squared=False)\n",
    "    MAE = metrics.mean_absolute_error(target_test, target_predict)\n",
    "    R2 = metrics.r2_score(target_test, target_predict)\n",
    "\n",
    "    return MSE, MAE, R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"LinearRegression\" : LinearRegression(),\n",
    "          \"Ridge\" : Ridge(),\n",
    "          \"Lasso\" : Lasso(),\n",
    "          \"ElasticNet\" : ElasticNet()}\n",
    "\n",
    "p_grid = {\"LinearRegression\" : [{}],\n",
    "          \"Ridge\" : [{\"alpha\" : x} for x in [.1, .5, 1, 5, 10, 50, 100, 500, 1000]],\n",
    "          \"Lasso\" : [{\"alpha\" : x} for x in [.1, .5, 1, 5, 10, 50, 100, 500, 1000]],\n",
    "          \"ElasticNet\" : [{\"alpha\" : x,\n",
    "                         \"l1_ratio\" : y} \n",
    "                          for x in [.1, 1, 10, 100, 1000] \n",
    "                          for y in [.1, .3, .5, .7, .9]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     Unnamed: 0      ndvi      ndsi      ndbi    albedo      awei      gemi  \\\n",
      "462   -1.235573 -0.139697  0.268998 -0.171601 -0.381490 -0.180592  0.097757   \n",
      "463   -1.232360  0.722735 -0.489520 -0.905090 -0.639338 -0.638493  0.635306   \n",
      "464   -1.229146  1.213827 -1.033496 -1.099187 -0.679499 -0.867479  1.034801   \n",
      "465   -1.225933  1.177279 -0.924053 -1.189886 -0.770374 -0.849653  0.852230   \n",
      "466   -1.222719  0.248333 -0.396686  0.115365 -0.938576 -0.643018 -0.080626   \n",
      "..          ...       ...       ...       ...       ...       ...       ...   \n",
      "611   -0.756768  1.197769 -1.185836 -0.909430 -0.895482 -0.955465  0.739258   \n",
      "612   -0.753555  1.599913 -1.450158 -1.477760 -0.764670 -1.053761  1.253076   \n",
      "613   -0.750341  1.751269 -1.450444 -1.873732 -0.893115 -1.079826  1.173598   \n",
      "614   -0.747128  0.537649 -0.822523  0.346960 -0.064369 -0.580049  1.021475   \n",
      "615   -0.743915  0.380359 -0.580195  0.193290 -0.790011 -0.662362  0.202373   \n",
      "\n",
      "     ndvi_lag  ndsi_lag  ndbi_lag  albedo_lag  awei_lag  gemi_lag   LST_lag  \\\n",
      "462  0.612993 -0.571973 -0.430542   -0.802885 -0.727436  0.523565 -1.808261   \n",
      "463  0.846039 -0.623576 -1.002049   -0.724476 -0.731641  0.813862 -2.075126   \n",
      "464  0.575843 -0.661407 -0.119765   -0.976146 -0.797259  0.270755 -1.296272   \n",
      "465  0.734796 -0.706055 -0.509872   -0.891824 -0.809991  0.540911 -1.389834   \n",
      "466  0.430217 -0.613710  0.152211   -0.944720 -0.758154  0.180333 -1.163880   \n",
      "..        ...       ...       ...         ...       ...       ...       ...   \n",
      "611  1.891521 -1.558262 -2.118443   -1.066678 -1.205179  1.310342 -0.677002   \n",
      "612  2.502001 -1.839702 -3.370740   -1.110805 -1.341485  1.767050 -0.929417   \n",
      "613  1.926088 -1.586512 -2.147788   -1.028379 -1.214410  1.415468 -0.633042   \n",
      "614  1.323028 -1.141233 -1.483912   -0.959518 -1.026014  1.009023 -0.613651   \n",
      "615  0.834159 -0.582654 -1.046248   -0.690552 -0.708480  0.839715 -2.237238   \n",
      "\n",
      "     community  period  \n",
      "462  -1.709701    -1.0  \n",
      "463  -1.664709    -1.0  \n",
      "464  -1.619717    -1.0  \n",
      "465  -1.574724    -1.0  \n",
      "466  -1.529732    -1.0  \n",
      "..         ...     ...  \n",
      "611   1.529732     1.0  \n",
      "612   1.574724     1.0  \n",
      "613   1.619717     1.0  \n",
      "614   1.664709     1.0  \n",
      "615   1.709701     1.0  \n",
      "\n",
      "[154 rows x 16 columns],       Unnamed: 0      ndvi      ndsi      ndbi    albedo      awei      gemi  \\\n",
      "462    -0.463313  0.314291 -0.290707 -0.044559 -0.627675 -0.560334  0.468068   \n",
      "463    -0.460728  0.952218 -0.770444 -0.614211 -0.705338 -0.695140  0.515344   \n",
      "464    -0.458142  1.315471 -1.114491 -0.764953 -0.717434 -0.762553  0.550479   \n",
      "465    -0.455556  1.288437 -1.045272 -0.835392 -0.744805 -0.757305  0.534423   \n",
      "466    -0.452970  0.601311 -0.711730  0.178307 -0.795467 -0.696472  0.452379   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "1227    1.514927  0.290890 -0.227450 -0.181703 -0.329079 -0.429653  0.507394   \n",
      "1228    1.517513  1.076395 -0.703297 -0.974473 -0.633498 -0.659122  0.561264   \n",
      "1229    1.520099  0.177228  0.120436 -0.727194 -0.240183 -0.302209  0.494740   \n",
      "1230    1.522685  0.004535 -0.130045  0.398177 -0.180123 -0.315017  0.465771   \n",
      "1231    1.525271 -0.203112  0.172017  0.546306 -0.442009 -0.334510  0.426121   \n",
      "\n",
      "      ndvi_lag  ndsi_lag  ndbi_lag  albedo_lag  awei_lag  gemi_lag   LST_lag  \\\n",
      "462   0.889765 -0.840665 -0.227235   -0.772284 -0.737580  0.574989  0.210024   \n",
      "463   1.054300 -0.871862 -0.787342   -0.750826 -0.738701  0.597018  0.149460   \n",
      "464   0.863536 -0.894732  0.077343   -0.819701 -0.756182  0.555805  0.326218   \n",
      "465   0.975760 -0.921723 -0.304982   -0.796625 -0.759575  0.576305  0.304984   \n",
      "466   0.760722 -0.865897  0.343894   -0.811101 -0.745764  0.548943  0.356263   \n",
      "...        ...       ...       ...         ...       ...       ...       ...   \n",
      "1227  0.418294 -0.170079 -0.873492   -0.387628 -0.449542  0.591247  0.824379   \n",
      "1228  0.574824 -0.190447 -1.426126   -0.406075 -0.472029  0.613743  0.730186   \n",
      "1229  0.733269 -0.465820 -0.971060   -0.509088 -0.579317  0.625451  0.943303   \n",
      "1230  0.459472 -0.323212 -0.530713   -0.387427 -0.495066  0.604989  0.956645   \n",
      "1231 -0.059853  0.079470  0.229828   -0.313057 -0.339037  0.529247  0.763775   \n",
      "\n",
      "      community  period  \n",
      "462   -1.709701    -1.0  \n",
      "463   -1.664709    -1.0  \n",
      "464   -1.619717    -1.0  \n",
      "465   -1.574724    -1.0  \n",
      "466   -1.529732    -1.0  \n",
      "...         ...     ...  \n",
      "1227   1.529732     1.0  \n",
      "1228   1.574724     1.0  \n",
      "1229   1.619717     1.0  \n",
      "1230   1.664709     1.0  \n",
      "1231   1.709701     1.0  \n",
      "\n",
      "[308 rows x 16 columns],      Unnamed: 0      ndvi      ndsi      ndbi    albedo      awei      gemi  \\\n",
      "462   -0.325265  0.449617 -0.365722 -0.171540 -0.703520 -0.621203  0.492117   \n",
      "463   -0.322437  1.122098 -0.860684 -0.712117 -0.781477 -0.756991  0.538414   \n",
      "464   -0.319608  1.505027 -1.215649 -0.855165 -0.793620 -0.824896  0.572821   \n",
      "465   -0.316780  1.476529 -1.144234 -0.922009 -0.821095 -0.819609  0.557097   \n",
      "466   -0.313952  0.752183 -0.800106  0.039951 -0.871949 -0.758333  0.476754   \n",
      "..          ...       ...       ...       ...       ...       ...       ...   \n",
      "303   -0.774980 -0.826747  0.350497  1.571076  0.726797  0.648113 -0.128985   \n",
      "304   -0.772151 -0.664908 -0.586587  4.161867  0.183186 -0.064732  0.233578   \n",
      "305   -0.769323 -1.377814  1.557547 -0.520871  1.962484  2.165650 -2.504760   \n",
      "306   -0.766495 -3.716278  1.490950  6.542044 -2.072423 -1.464470 -0.596151   \n",
      "307   -0.763666  0.113841 -0.389526  1.034552 -0.173229 -0.385110  0.488013   \n",
      "\n",
      "     ndvi_lag  ndsi_lag  ndbi_lag  albedo_lag  awei_lag  gemi_lag   LST_lag  \\\n",
      "462  1.075359 -0.963895 -0.422025   -0.864340 -0.819920  0.620937  0.521772   \n",
      "463  1.249391 -0.997108 -0.923878   -0.842481 -0.821078  0.643563  0.481653   \n",
      "464  1.047617 -1.021456 -0.149125   -0.912640 -0.839148  0.601233  0.598741   \n",
      "465  1.166318 -1.050192 -0.491687   -0.889134 -0.842654  0.622289  0.584675   \n",
      "466  0.938868 -0.990758  0.089702   -0.903879 -0.828379  0.594185  0.618643   \n",
      "..        ...       ...       ...         ...       ...       ...       ...   \n",
      "303 -1.438660  1.561968 -0.537008    1.769829  1.922545 -1.919130 -0.706608   \n",
      "304 -1.420585  1.300783  0.556751    1.672867  1.794797 -1.908027 -0.685094   \n",
      "305 -1.086255  0.762578  1.548081    0.920957  0.914190 -0.420846 -0.648819   \n",
      "306  1.000915 -0.749098 -0.632103   -0.464775 -0.641826  0.697842  0.535390   \n",
      "307  1.068312 -0.904079  0.177395   -0.580318 -0.713283  0.694071  0.470839   \n",
      "\n",
      "     community  period  \n",
      "462  -1.709701    -1.0  \n",
      "463  -1.664709    -1.0  \n",
      "464  -1.619717    -1.0  \n",
      "465  -1.574724    -1.0  \n",
      "466  -1.529732    -1.0  \n",
      "..         ...     ...  \n",
      "303   1.529732     1.0  \n",
      "304   1.574724     1.0  \n",
      "305   1.619717     1.0  \n",
      "306   1.664709     1.0  \n",
      "307   1.709701     1.0  \n",
      "\n",
      "[462 rows x 16 columns],      Unnamed: 0      ndvi      ndsi      ndbi    albedo      awei      gemi  \\\n",
      "462   -0.431284  0.646947 -0.604428  0.260125 -0.902840 -0.825149  0.645783   \n",
      "463   -0.428161  1.257070 -0.925166  0.067780 -0.970757 -0.932136  0.681004   \n",
      "464   -0.425038  1.604490 -1.155186  0.016881 -0.981336 -0.985638  0.707180   \n",
      "465   -0.421915  1.578634 -1.108908 -0.006903 -1.005272 -0.981473  0.695217   \n",
      "466   -0.418792  0.921457 -0.885912  0.335377 -1.049576 -0.933193  0.634095   \n",
      "..          ...       ...       ...       ...       ...       ...       ...   \n",
      "457   -0.446899 -0.012607 -0.262753  0.429100 -0.483494 -0.533011  0.592148   \n",
      "458   -0.443776  0.737543 -0.770684  0.469865 -0.744896 -0.802964  0.678467   \n",
      "459   -0.440653  0.981442 -0.831929  0.256550 -0.940912 -0.892054  0.667700   \n",
      "460   -0.437530 -0.843216  0.505784  0.128099  0.828571  0.613697 -0.094578   \n",
      "461   -0.434407 -0.239476  0.042394 -0.103881  0.483815  0.233426  0.059872   \n",
      "\n",
      "     ndvi_lag  ndsi_lag  ndbi_lag  albedo_lag  awei_lag  gemi_lag   LST_lag  \\\n",
      "462  1.262968 -1.003998  0.289868   -1.050605 -0.980805  0.762237  0.748053   \n",
      "463  1.422293 -1.024921  0.142561   -1.031856 -0.981690  0.778430  0.721320   \n",
      "464  1.237570 -1.040260  0.369972   -1.092032 -0.995506  0.748135  0.799342   \n",
      "465  1.346240 -1.058364  0.269420   -1.071871 -0.998187  0.763205  0.789969   \n",
      "466  1.138012 -1.020921  0.440074   -1.084518 -0.987272  0.743091  0.812604   \n",
      "..        ...       ...       ...         ...       ...       ...       ...   \n",
      "457  0.738997 -0.630678  0.291474   -0.767966 -0.729302  0.671729  0.049647   \n",
      "458  1.406297 -0.969816  0.120994   -1.076615 -0.979405  0.763269  0.421879   \n",
      "459  0.402628 -0.453845  0.378388   -0.528437 -0.587369  0.665175 -0.163973   \n",
      "460 -1.066878  0.779419 -0.177882    1.373176  1.257940 -1.247293 -1.206054   \n",
      "461 -0.027404 -0.616989  0.848621    0.350086 -0.060154 -0.553964 -1.357672   \n",
      "\n",
      "     community  period  \n",
      "462  -1.709701    -1.0  \n",
      "463  -1.664709    -1.0  \n",
      "464  -1.619717    -1.0  \n",
      "465  -1.574724    -1.0  \n",
      "466  -1.529732    -1.0  \n",
      "..         ...     ...  \n",
      "457   1.529732     1.0  \n",
      "458   1.574724     1.0  \n",
      "459   1.619717     1.0  \n",
      "460   1.664709     1.0  \n",
      "461   1.709701     1.0  \n",
      "\n",
      "[616 rows x 16 columns],      Unnamed: 0      ndvi      ndsi       ndbi    albedo      awei      gemi  \\\n",
      "462   -0.583741  0.708207 -0.648397   0.217583 -0.930000 -0.850838  0.626265   \n",
      "463   -0.580483  1.345502 -0.992511   0.011521 -1.001530 -0.964397  0.664066   \n",
      "464   -0.577224  1.708395 -1.239295  -0.043008 -1.012671 -1.021185  0.692159   \n",
      "465   -0.573966  1.681388 -1.189644  -0.068488 -1.037880 -1.016764  0.679321   \n",
      "466   -0.570708  0.994942 -0.950395   0.298201 -1.084541 -0.965519  0.613721   \n",
      "..          ...       ...       ...        ...       ...       ...       ...   \n",
      "765    0.403460 -1.072245  1.616798  -1.510208  1.596283  1.754706 -1.587914   \n",
      "766    0.406718 -0.899262  1.328904  -1.188653  1.126608  1.177862 -0.480086   \n",
      "767    0.409976 -1.001895  1.367693  -1.147002  1.522030  1.557027 -1.233017   \n",
      "768    0.413234  5.819347 -4.620568  11.389026 -1.723153 -1.053130  0.297456   \n",
      "769    0.416492 -1.070190  1.035722  -0.473119  1.087253  1.091772 -0.502467   \n",
      "\n",
      "     ndvi_lag  ndsi_lag  ndbi_lag  albedo_lag  awei_lag  gemi_lag   LST_lag  \\\n",
      "462  1.398360 -1.096460  0.226223   -1.119792 -1.040476  0.744173  0.705336   \n",
      "463  1.568815 -1.119230  0.068803   -1.099498 -1.041436  0.761602  0.676857   \n",
      "464  1.371187 -1.135922  0.311826   -1.164634 -1.056410  0.728995  0.759975   \n",
      "465  1.487449 -1.155623  0.204372   -1.142810 -1.059316  0.745215  0.749991   \n",
      "466  1.264674 -1.114876  0.386741   -1.156501 -1.047486  0.723567  0.774104   \n",
      "..        ...       ...       ...         ...       ...       ...       ...   \n",
      "765 -1.197319  1.714603 -1.845242    1.682837  1.826540 -1.904587 -1.883439   \n",
      "766 -1.132892  1.508083 -1.494245    1.506912  1.562748 -1.158398 -1.750494   \n",
      "767 -1.156613  1.661840 -1.780495    1.498042  1.634823 -1.279501 -1.790203   \n",
      "768 -0.987541  0.960925 -0.580118    1.017688  0.911560 -0.269665 -1.513048   \n",
      "769 -1.240784  1.238880 -0.808249    1.516163  1.497621 -1.232876 -1.704591   \n",
      "\n",
      "     community  period  \n",
      "462  -1.709701    -1.0  \n",
      "463  -1.664709    -1.0  \n",
      "464  -1.619717    -1.0  \n",
      "465  -1.574724    -1.0  \n",
      "466  -1.529732    -1.0  \n",
      "..         ...     ...  \n",
      "765   1.529732     1.0  \n",
      "766   1.574724     1.0  \n",
      "767   1.619717     1.0  \n",
      "768   1.664709     1.0  \n",
      "769   1.709701     1.0  \n",
      "\n",
      "[770 rows x 16 columns]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'RMSE': 5.988882277443004,\n",
       "  'MAE': 4.76633515321592,\n",
       "  'r^2': 0.8455222698453201}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_models = []\n",
    "test_results, best, df_test_x, df_test_y, test_predictions = choose_and_test_model(df, models, p_grid, default_split)\n",
    "top_models.append(test_results)\n",
    "display(top_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     community  Prediction LST  Actual LST\n",
      "770          1      280.262253  279.499643\n",
      "771          2      275.267783  268.034657\n",
      "772          3      309.094408  305.745349\n",
      "773          4      286.415587  288.083356\n",
      "774          5      279.094105  280.788542\n",
      "..         ...             ...         ...\n",
      "919         73      290.253365  296.373129\n",
      "920         74      288.565655  295.832829\n",
      "921         75      292.309602  286.902977\n",
      "922         76      294.261798  303.468748\n",
      "923         77      295.060373  302.552540\n",
      "\n",
      "[154 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "community_col = df_test_x.community\n",
    "predict_col = pd.DataFrame(test_predictions)\n",
    "predict_col.index = community_col.index\n",
    "actual_col = pd.DataFrame(df_test_y)\n",
    "frames = [community_col, predict_col, actual_col]\n",
    "model_to_map_df = pd.concat(frames, axis=1)\n",
    "model_to_map_df = model_to_map_df.rename(columns={0: \"Prediction LST\", \"LST\": \"Actual LST\"})\n",
    "\n",
    "unique_norm_community_vals = np.sort(community_col.unique())\n",
    "real_com_values = list(range(1,78))\n",
    "replacement_dict = {}\n",
    "\n",
    "keys_list = unique_norm_community_vals\n",
    "values_list = real_com_values\n",
    "zip_iterator = zip(keys_list, values_list)\n",
    "replacement_dict = dict(zip_iterator)\n",
    "\n",
    "model_to_map_df[\"community\"] = model_to_map_df[\"community\"].map(replacement_dict)\n",
    "print(model_to_map_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_map_df.to_csv(\"model_predictions_by_community\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     community  Prediction LST  Actual LST\n",
      "770          1      280.262253  279.499643\n",
      "771          2      275.267783  268.034657\n",
      "772          3      309.094408  305.745349\n",
      "773          4      286.415587  288.083356\n",
      "774          5      279.094105  280.788542\n",
      "..         ...             ...         ...\n",
      "919         73      290.253365  296.373129\n",
      "920         74      288.565655  295.832829\n",
      "921         75      292.309602  286.902977\n",
      "922         76      294.261798  303.468748\n",
      "923         77      295.060373  302.552540\n",
      "\n",
      "[154 rows x 3 columns]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model                  Ridge\n",
       "Params          {'alpha': 1}\n",
       "RMSE               12.661043\n",
       "RMSE std dev        5.225271\n",
       "MAE                 7.835059\n",
       "R^2                -0.439518\n",
       "Name: 3, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'The above model produced the following metrics for LST:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'RMSE': 5.988882277443004, 'MAE': 4.76633515321592, 'r^2': 0.8455222698453201}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276.89339360051713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-230-a27a5406c55d>:164: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  df_tv_y = [pd.Series()]*k\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The coefficient values are as follows:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LST_lag</th>\n",
       "      <td>32.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndsi_lag</th>\n",
       "      <td>12.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndbi_lag</th>\n",
       "      <td>10.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awei_lag</th>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndvi</th>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           coef\n",
       "LST_lag   32.38\n",
       "ndsi_lag  12.66\n",
       "ndbi_lag  10.38\n",
       "awei_lag   3.56\n",
       "ndvi       1.06"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>albedo_lag</th>\n",
       "      <td>-1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awei</th>\n",
       "      <td>-2.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndvi_lag</th>\n",
       "      <td>-2.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndbi</th>\n",
       "      <td>-13.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndsi</th>\n",
       "      <td>-15.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             coef\n",
       "albedo_lag  -1.67\n",
       "awei        -2.08\n",
       "ndvi_lag    -2.19\n",
       "ndbi       -13.37\n",
       "ndsi       -15.73"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(best)\n",
    "display(\"The above model produced the following metrics for LST:\")\n",
    "display(test_results)\n",
    "coefs, results = find_features(df, best)\n",
    "display(\"The coefficient values are as follows:\")\n",
    "display(coefs.head(5))\n",
    "display(coefs.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LST_lag</th>\n",
       "      <td>32.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndsi_lag</th>\n",
       "      <td>12.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndbi_lag</th>\n",
       "      <td>10.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awei_lag</th>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndvi</th>\n",
       "      <td>1.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           coef\n",
       "LST_lag   32.38\n",
       "ndsi_lag  12.66\n",
       "ndbi_lag  10.38\n",
       "awei_lag   3.56\n",
       "ndvi       1.06"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "\n",
    "top_pos_coefs = coefs.head(5)\n",
    "labels = top_pos_coefs.index.values\n",
    "display(top_pos_coefs)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(labels,top_pos_coefs['coef'], color='green')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel(\"Coef Type\")\n",
    "plt.ylabel(\"Coef Size\")\n",
    "plt.title(\"Positive Coefficients for Best Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>albedo_lag</th>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awei</th>\n",
       "      <td>2.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndvi_lag</th>\n",
       "      <td>2.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndbi</th>\n",
       "      <td>13.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ndsi</th>\n",
       "      <td>15.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             coef\n",
       "albedo_lag   1.67\n",
       "awei         2.08\n",
       "ndvi_lag     2.19\n",
       "ndbi        13.37\n",
       "ndsi        15.73"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_neg_coefs = coefs.tail(5).abs()\n",
    "labels = top_neg_coefs.index.values\n",
    "display(top_neg_coefs)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(labels,top_neg_coefs['coef'], color='red')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel(\"Coef Type\")\n",
    "plt.ylabel(\"Coef Size\")\n",
    "plt.title(\"Negative Coefficients for Best Model\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
